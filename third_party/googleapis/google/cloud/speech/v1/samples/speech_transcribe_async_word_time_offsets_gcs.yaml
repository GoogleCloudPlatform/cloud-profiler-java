samples:
- id: speech_transcribe_async_word_time_offsets_gcs
  title: Getting word timestamps (Cloud Storage) (LRO)
  description: |
    Print start and end time of each word spoken in audio file from Cloud Storage
  rpc: LongRunningRecognize
  service: google.cloud.speech.v1.Speech
  parameters:
    defaults:
    - audio.uri = "gs://cloud-samples-data/speech/brooklyn_bridge.flac"
    - config.enable_word_time_offsets = True
    - config.language_code = "en-US"
    attributes:
    - parameter: audio.uri
      sample_argument_name: storage_uri
      description: "URI for audio file in Cloud Storage, e.g. gs://[BUCKET]/[FILE]"
    - parameter: config.enable_word_time_offsets
      description: |
        When enabled, the first result returned by the API will include a list
        of words and the start and end time offsets (timestamps) for those words.
    - parameter: config.language_code
      description: "The language of the supplied audio"
  on_success:
  - comment: ["The first result includes start and end time word offsets"]
  - define: result=$resp.results[0]
  - comment: ["First alternative is the most probable result"]
  - define: alternative=result.alternatives[0]
  - print:
    - "Transcript: %s"
    - alternative.transcript
  - comment: ["Print the start and end time of each word"]
  - loop:
      collection: alternative.words
      variable: word
      body:
      - print: ["Word: %s", word.word]
      - print: ["Start time: %s seconds %s nanos", word.start_time.seconds, word.start_time.nanos]
      - print: ["End time: %s seconds %s nanos", word.end_time.seconds, word.end_time.nanos]
