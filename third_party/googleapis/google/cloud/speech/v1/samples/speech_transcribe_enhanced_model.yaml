samples:
- id: speech_transcribe_enhanced_model
  title: Using Enhanced Models (Local File)
  description: Transcribe a short audio file using an enhanced model
  rpc: Recognize
  service: google.cloud.speech.v1.Speech
  parameters:
    defaults:
    - audio.content = "resources/hello.wav"
    - config.model = "phone_call"
    - config.use_enhanced = True
    - config.language_code = "en-US"
    attributes:
    - parameter: audio.content
      sample_argument_name: local_file_path
      read_file: true
      description: "Path to local audio file, e.g. /path/audio.wav"
    - parameter: config.model
      description: |
        The enhanced model to use, e.g. phone_call
        Currently phone_call is the only model available as an enhanced model.
    - parameter: config.use_enhanced
      description: |
        Use an enhanced model for speech recognition (when set to true).
        Project must be eligible for requesting enhanced models.
        Enhanced speech models require that you opt-in to data logging.
    - parameter: config.language_code
      description: "The language of the supplied audio"
  on_success:
  - loop:
      variable: result
      collection: $resp.results
      body:
      - comment: ["First alternative is the most probable result"]
      - define: alternative=result.alternatives[0]
      - print:
        - "Transcript: %s"
        - alternative.transcript
