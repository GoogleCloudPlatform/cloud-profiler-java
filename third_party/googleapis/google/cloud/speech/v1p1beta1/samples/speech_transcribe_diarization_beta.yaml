samples:
# TODO: this id should include "async" (calls LongRunningRecognize async rpc)
- id: speech_transcribe_diarization_beta
  title: Separating different speakers (Local File) (LRO) (Beta)
  description: |
    Print confidence level for individual words in a transcription of a short audio file
    Separating different speakers in an audio file recording
  rpc: LongRunningRecognize
  service: google.cloud.speech.v1p1beta1.Speech
  parameters:
    defaults:
    - audio.content = "resources/commercial_mono.wav"
    - config.enable_speaker_diarization = True
    - config.diarization_speaker_count = 2
    - config.language_code = "en-US"
    attributes:
    - parameter: audio.content
      sample_argument_name: local_file_path
      read_file: true
      description: "Path to local audio file, e.g. /path/audio.wav"
    - parameter: config.enable_speaker_diarization
      description: |
        If enabled, each word in the first alternative of each result will be
        tagged with a speaker tag to identify the speaker.
    - parameter: config.diarization_speaker_count
      description: |
        Optional. Specifies the estimated number of speakers in the conversation.
    - parameter: config.language_code
      description: "The language of the supplied audio"
  on_success:
  - loop:
      collection: $resp.results
      variable: result
      body:
      - comment: ["First alternative has words tagged with speakers"]
      - define: alternative=result.alternatives[0]
      - print:
        - "Transcript: %s"
        - alternative.transcript
      - comment: ["Print the %s of each word", speaker_tag]
      - loop:
          collection: alternative.words
          variable: word
          body:
          - print: ["Word: %s", word.word]
          - print: ["Speaker tag: %s", word.speaker_tag]
