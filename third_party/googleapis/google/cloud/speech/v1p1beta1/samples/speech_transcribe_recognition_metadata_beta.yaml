samples:
- id: speech_transcribe_recognition_metadata_beta
  title: Adding recognition metadata (Local File) (Beta)
  description: |
    Adds additional details short audio file included in this recognition request
  rpc: Recognize
  service: google.cloud.speech.v1p1beta1.Speech
  parameters:
    defaults:
    - audio.content = "resources/commercial_mono.wav"
    - config.metadata.interaction_type = VOICE_SEARCH
    - config.metadata.recording_device_type = SMARTPHONE
    - config.metadata.recording_device_name = "Pixel 3"
    - config.language_code = "en-US"
    attributes:
    - parameter: audio.content
      sample_argument_name: local_file_path
      read_file: true
      description: "Path to local audio file, e.g. /path/audio.wav"
    - parameter: config.metadata.interaction_type
      description: |
        The use case of the audio, e.g. PHONE_CALL, DISCUSSION, PRESENTATION, et al.
    - parameter: config.metadata.recording_device_type
      description: The kind of device used to capture the audio
    - parameter: config.metadata.recording_device_name
      description: |
        The device used to make the recording.
        Arbitrary string, e.g. 'Pixel XL', 'VoIP', 'Cardioid Microphone', or other value.
    - parameter: config.language_code
      description: |
        The language of the supplied audio. Even though additional languages are
        provided by alternative_language_codes, a primary language is still required.
  on_success:
  - loop:
      variable: result
      collection: $resp.results
      body:
      - comment: ["First alternative is the most probable result"]
      - define: alternative=result.alternatives[0]
      - print:
        - "Transcript: %s"
        - alternative.transcript
